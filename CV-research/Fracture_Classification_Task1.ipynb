{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6997161,"sourceType":"datasetVersion","datasetId":4022240}],"dockerImageVersionId":30589,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, models, transforms\nfrom torchvision.models.resnet import ResNet50_Weights\nfrom torchvision.models.densenet import DenseNet121_Weights\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True","metadata":{"id":"KAYT3C8zL0EM","execution":{"iopub.status.busy":"2023-11-21T07:24:28.811611Z","iopub.execute_input":"2023-11-21T07:24:28.811895Z","iopub.status.idle":"2023-11-21T07:24:33.217350Z","shell.execute_reply.started":"2023-11-21T07:24:28.811870Z","shell.execute_reply":"2023-11-21T07:24:33.216530Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# cuda availability\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# transforming to imagenet format\ntransform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n","metadata":{"id":"j9Z054vfNIyu","execution":{"iopub.status.busy":"2023-11-21T07:24:33.218885Z","iopub.execute_input":"2023-11-21T07:24:33.219300Z","iopub.status.idle":"2023-11-21T07:24:33.292721Z","shell.execute_reply.started":"2023-11-21T07:24:33.219274Z","shell.execute_reply":"2023-11-21T07:24:33.291714Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Loading the dataset\ntrain_dataset = datasets.ImageFolder(\"/kaggle/input/fractatlas/train\", transform=transform) #Update the path to dataset\nval_dataset = datasets.ImageFolder(\"/kaggle/input/fractatlas/val\", transform=transform) #Update the path to dataset\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)","metadata":{"id":"3CTFajkcNTp5","execution":{"iopub.status.busy":"2023-11-21T07:24:33.294449Z","iopub.execute_input":"2023-11-21T07:24:33.294796Z","iopub.status.idle":"2023-11-21T07:24:34.494975Z","shell.execute_reply.started":"2023-11-21T07:24:33.294770Z","shell.execute_reply":"2023-11-21T07:24:34.494205Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Resnet","metadata":{}},{"cell_type":"code","source":"# Pretrained, SOTA resnet model for imagenet\nmodel = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n\n# freezing all layers in the model\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Replacing number of classes to classify into, to our desired number\nnum_classes = 2 # Binary Classification - Fractured or Non_Fractured\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, num_classes)\nmodel = model.to(device)\n","metadata":{"id":"syrQFNP4NW9H","outputId":"3a753e5e-bcfd-4d4c-a935-a28221585b5b","execution":{"iopub.status.busy":"2023-11-21T07:24:34.497440Z","iopub.execute_input":"2023-11-21T07:24:34.497827Z","iopub.status.idle":"2023-11-21T07:24:39.356893Z","shell.execute_reply.started":"2023-11-21T07:24:34.497795Z","shell.execute_reply":"2023-11-21T07:24:39.355902Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 178MB/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"# loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)","metadata":{"id":"jALJznf1N2zv","execution":{"iopub.status.busy":"2023-11-21T07:24:39.357951Z","iopub.execute_input":"2023-11-21T07:24:39.358244Z","iopub.status.idle":"2023-11-21T07:24:39.363309Z","shell.execute_reply.started":"2023-11-21T07:24:39.358220Z","shell.execute_reply":"2023-11-21T07:24:39.362114Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# fine tuning step\n\nnum_epochs = 3\ni=0\nfor epoch in range(num_epochs):\n    model.train()\n    for inputs, labels in train_loader:\n        try:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            i+=1\n\n        except OSError as e:\n            print(\"Skipping a corrupted image\", i)\n\n    # Validation Accuracy\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n\n    print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Accuracy: {100 * correct / total:.2f}%\")\n","metadata":{"id":"g0EHcDAPN5LN","outputId":"b9b2d825-70ca-471c-fbaf-6144a593d650","execution":{"iopub.status.busy":"2023-11-21T07:24:39.364593Z","iopub.execute_input":"2023-11-21T07:24:39.365166Z","iopub.status.idle":"2023-11-21T07:27:19.351683Z","shell.execute_reply.started":"2023-11-21T07:24:39.365131Z","shell.execute_reply":"2023-11-21T07:27:19.350688Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Epoch 1/3, Validation Accuracy: 82.38%\nEpoch 2/3, Validation Accuracy: 82.38%\nEpoch 3/3, Validation Accuracy: 82.54%\n","output_type":"stream"}]},{"cell_type":"code","source":"# Saving the model\ntorch.save(model, '/kaggle/working/model_resnet50.pth')","metadata":{"execution":{"iopub.status.busy":"2023-11-21T07:27:19.352969Z","iopub.execute_input":"2023-11-21T07:27:19.353333Z","iopub.status.idle":"2023-11-21T07:27:19.518412Z","shell.execute_reply.started":"2023-11-21T07:27:19.353301Z","shell.execute_reply":"2023-11-21T07:27:19.517571Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## DenseNet","metadata":{}},{"cell_type":"code","source":"# Pretrained, densenet model for imagenet\ndensenet_model = models.densenet121(weights=DenseNet121_Weights.IMAGENET1K_V1)\n\n\n# freezing all layers in the model\nfor param in densenet_model.parameters():\n    param.requires_grad = False\n\n# Replacing number of classes to classify into, to our desired number\nnum_classes = 2  # Binary Classification - Fractured or Non_Fractured\nnum_ftrs = densenet_model.classifier.in_features\ndensenet_model.classifier = nn.Linear(num_ftrs, num_classes)\ndensenet_model = densenet_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T07:27:19.519501Z","iopub.execute_input":"2023-11-21T07:27:19.519797Z","iopub.status.idle":"2023-11-21T07:27:20.091849Z","shell.execute_reply.started":"2023-11-21T07:27:19.519773Z","shell.execute_reply":"2023-11-21T07:27:20.091114Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n100%|██████████| 30.8M/30.8M [00:00<00:00, 149MB/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"# loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(densenet_model.parameters(), lr=0.001, momentum=0.9)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T07:27:20.092851Z","iopub.execute_input":"2023-11-21T07:27:20.093129Z","iopub.status.idle":"2023-11-21T07:27:20.100588Z","shell.execute_reply.started":"2023-11-21T07:27:20.093107Z","shell.execute_reply":"2023-11-21T07:27:20.099402Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# fine tuning step\n\nnum_epochs = 3\ni=0\nfor epoch in range(num_epochs):\n    densenet_model.train()\n    for inputs, labels in train_loader:\n        try:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = densenet_model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            i+=1\n\n        except OSError as e:\n            print(\"Skipping a corrupted image\", i)\n\n    # Validation Accuracy\n    densenet_model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = densenet_model(inputs)\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n\n    print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Accuracy: {100 * correct / total:.2f}%\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T07:27:20.103007Z","iopub.execute_input":"2023-11-21T07:27:20.103292Z","iopub.status.idle":"2023-11-21T07:29:43.938063Z","shell.execute_reply.started":"2023-11-21T07:27:20.103268Z","shell.execute_reply":"2023-11-21T07:29:43.936970Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 1/3, Validation Accuracy: 83.03%\nEpoch 2/3, Validation Accuracy: 86.30%\nEpoch 3/3, Validation Accuracy: 86.30%\n","output_type":"stream"}]},{"cell_type":"code","source":"# Saving the model\ntorch.save(model, '/kaggle/working/model_densenet121.pth')","metadata":{"execution":{"iopub.status.busy":"2023-11-21T07:30:35.331865Z","iopub.execute_input":"2023-11-21T07:30:35.333017Z","iopub.status.idle":"2023-11-21T07:30:35.513045Z","shell.execute_reply.started":"2023-11-21T07:30:35.332949Z","shell.execute_reply":"2023-11-21T07:30:35.511921Z"},"trusted":true},"execution_count":11,"outputs":[]}]}