{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Helenessli/BreakingTheBinary/blob/main/Step_2_Multiclass_Classifier_3epochs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIOJr5RpYaTf",
        "outputId": "07b6cfc7-8036-4cdf-fe87-c74aad4184e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gIihXIrYcfC",
        "outputId": "1d09fe7c-5649-48a7-bae1-49d30fe1b0fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      SOPInstanceUID Target  MultiImageType  \\\n",
            "0  1.2.826.0.1.3680043.8.498.10025629581362719970...     0              1.0   \n",
            "1  1.2.826.0.1.3680043.8.498.10036150326276641158...    15              1.0   \n",
            "2  1.2.826.0.1.3680043.8.498.10038426859954986240...    12              1.0   \n",
            "3  1.2.826.0.1.3680043.8.498.10050991192143676483...    14              NaN   \n",
            "4  1.2.826.0.1.3680043.8.498.10053309524595490852...     3              1.0   \n",
            "\n",
            "  ImageType ImageType1  InstanceCreationDate  InstanceCreationTime  \\\n",
            "0  ORIGINAL    PRIMARY                   NaN                   NaN   \n",
            "1  ORIGINAL    PRIMARY                   NaN                   NaN   \n",
            "2  ORIGINAL    PRIMARY                   NaN                   NaN   \n",
            "3       NaN        NaN                   NaN                   NaN   \n",
            "4  ORIGINAL    PRIMARY                   NaN                   NaN   \n",
            "\n",
            "                 SOPClassUID  StudyDate  SeriesDate  ...  WindowWidth  \\\n",
            "0  1.2.840.10008.5.1.4.1.1.1        NaN         NaN  ...          NaN   \n",
            "1  1.2.840.10008.5.1.4.1.1.1        NaN         NaN  ...          NaN   \n",
            "2  1.2.840.10008.5.1.4.1.1.1        NaN         NaN  ...          NaN   \n",
            "3  1.2.840.10008.5.1.4.1.1.1        NaN         NaN  ...          NaN   \n",
            "4  1.2.840.10008.5.1.4.1.1.1        NaN         NaN  ...          NaN   \n",
            "\n",
            "   ImageType2  KVP  DistanceSourceToDetector DistanceSourceToPatient  \\\n",
            "0         NaN  NaN                       NaN                     NaN   \n",
            "1         NaN  NaN                       NaN                     NaN   \n",
            "2         NaN  NaN                       NaN                     NaN   \n",
            "3         NaN  NaN                       NaN                     NaN   \n",
            "4         NaN  NaN                       NaN                     NaN   \n",
            "\n",
            "   ExposureTime  XRayTubeCurrent  AcquisitionNumber ImageType3  \\\n",
            "0           NaN              NaN                NaN        NaN   \n",
            "1           NaN              NaN                NaN        NaN   \n",
            "2           NaN              NaN                NaN        NaN   \n",
            "3           NaN              NaN                NaN        NaN   \n",
            "4           NaN              NaN                NaN        NaN   \n",
            "\n",
            "                                          image_path  \n",
            "0  ./images/train/1.2.826.0.1.3680043.8.498.10025...  \n",
            "1  ./images/train/1.2.826.0.1.3680043.8.498.10036...  \n",
            "2  ./images/train/1.2.826.0.1.3680043.8.498.10038...  \n",
            "3  ./images/train/1.2.826.0.1.3680043.8.498.10050...  \n",
            "4  ./images/train/1.2.826.0.1.3680043.8.498.10053...  \n",
            "\n",
            "[5 rows x 65 columns]\n",
            "1606\n",
            "1284 322\n"
          ]
        }
      ],
      "source": [
        "# Trim the dataset so only images with one label are kept\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/Datasets/train_df.csv')\n",
        "df.head()\n",
        "len(df)\n",
        "new_df = df[df['Target'].str.len() <= 3]\n",
        "print(new_df.head())\n",
        "print(len(new_df))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(new_df, test_size=0.2)\n",
        "print(len(train), len(test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GJjWPxhsjaTE"
      },
      "outputs": [],
      "source": [
        "#SKIP THIS (only do it once)\n",
        "train.to_csv('traindf.csv')\n",
        "test.to_csv('testdf.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "C7ouV0BIYkfQ"
      },
      "outputs": [],
      "source": [
        "# Copy the dataset to Colab\n",
        "!cp -r '/content/drive/MyDrive/Datasets/images' '/content/'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Q1gqdR6iYmlY"
      },
      "outputs": [],
      "source": [
        "#basic imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.models.densenet import DenseNet121_Weights\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "iFWpEc_O1jHF"
      },
      "outputs": [],
      "source": [
        "# Obtain the labels of from csv file\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, csv_file, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.data.iloc[idx, 65]  # Assuming 'image_path' is in the 65th column\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "        label = torch.tensor(self.data.iloc[idx, 2], dtype=torch.long)  # Assuming 'Target' is in the second column\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "mx5XC4vRYoyy"
      },
      "outputs": [],
      "source": [
        "# cuda availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Transformations for the images\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rynQu9cW1sUP"
      },
      "outputs": [],
      "source": [
        "# Load the custom dataset\n",
        "#csv_file_path = 'train_df.csv'\n",
        "#custom_dataset = CustomImageDataset(csv_file=csv_file_path, transform=transform)\n",
        "\n",
        "# Initialize the CustomImageDataset\n",
        "train_dataset = CustomImageDataset(csv_file='traindf.csv', transform=transform)\n",
        "test_dataset = CustomImageDataset(csv_file='testdf.csv', transform=transform)\n",
        "\n",
        "# Accessing elements from the dataset\n",
        "#image, label = custom_dataset[0]  # Example: Accessing the first element in the dataset\n",
        "\n",
        "# Create DataLoader instances\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfNIdBKWYYWN",
        "outputId": "2224cb0f-4b2c-4c23-a9af-0ed277fbcd9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# Pretrained, densenet model for imagenet\n",
        "densenet_model = models.densenet121(weights=DenseNet121_Weights.IMAGENET1K_V1)\n",
        "\n",
        "\n",
        "# freezing all layers in the model\n",
        "for param in densenet_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Define the model (using a pre-trained DenseNet)\n",
        "num_classes = 22  # Number of body parts\n",
        "densenet_model = models.densenet121(pretrained=True)\n",
        "num_ftrs = densenet_model.classifier.in_features\n",
        "densenet_model.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "densenet_model = densenet_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "xqr4_gdXYTuI"
      },
      "outputs": [],
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(densenet_model.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejJ4LRFTQQ8J",
        "outputId": "d78ab854-eecb-4081-9098-78c14b1cb4a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Training Loss: 2.2168, Training Accuracy: 56.62%Test Accuracy: 60.56%\n",
            "Epoch 2/3, Training Loss: 1.4191, Training Accuracy: 74.30%Test Accuracy: 73.29%\n",
            "Epoch 3/3, Training Loss: 1.0654, Training Accuracy: 80.37%Test Accuracy: 78.26%\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    densenet_model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = densenet_model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Calculate training loss\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "\n",
        "  # Training accuracy\n",
        "    densenet_model.eval()\n",
        "    traincorrect = 0\n",
        "    traintotal = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = densenet_model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            traintotal += labels.size(0)\n",
        "            traincorrect += predicted.eq(labels).sum().item()\n",
        "\n",
        "    # Validation accuracy\n",
        "    densenet_model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = densenet_model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    # Print stats at the end of each epoch\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, \"\n",
        "          f\"Training Loss: {epoch_loss:.4f}, \"\n",
        "          f\"Training Accuracy: {100 * traincorrect / traintotal:.2f}%\"\n",
        "          f\"Test Accuracy: {100 * correct / total:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the model\n",
        "torch.save(densenet_model, '/content/drive/MyDrive/OutputModelBinaries/steptwo_3epochs.pth')"
      ],
      "metadata": {
        "id": "oATJLdmzk_Zg"
      },
      "execution_count": 24,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5pOhMZqCJQuX5e0R55MiA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}