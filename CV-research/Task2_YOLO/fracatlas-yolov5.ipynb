{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6696884,"sourceType":"datasetVersion","datasetId":3860653}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/ultralytics/yolov5  # clone repo\n!pip install -U -r yolov5/requirements.txt  # install dependencies\n%cd /content/yolov5","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-27T17:59:49.023422Z","iopub.execute_input":"2024-02-27T17:59:49.023877Z","iopub.status.idle":"2024-02-27T18:04:00.258792Z","shell.execute_reply.started":"2024-02-27T17:59:49.023838Z","shell.execute_reply":"2024-02-27T18:04:00.257645Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'yolov5'...\nremote: Enumerating objects: 16491, done.\u001b[K\nremote: Counting objects: 100% (83/83), done.\u001b[K\nremote: Compressing objects: 100% (74/74), done.\u001b[K\nremote: Total 16491 (delta 27), reused 35 (delta 9), pack-reused 16408\u001b[K\nReceiving objects: 100% (16491/16491), 15.11 MiB | 29.75 MiB/s, done.\nResolving deltas: 100% (11292/11292), done.\nRequirement already satisfied: gitpython>=3.1.30 in /opt/conda/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 5)) (3.1.41)\nCollecting gitpython>=3.1.30 (from -r yolov5/requirements.txt (line 5))\n  Downloading GitPython-3.1.42-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: matplotlib>=3.3 in /opt/conda/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 6)) (3.7.4)\nCollecting matplotlib>=3.3 (from -r yolov5/requirements.txt (line 6))\n  Downloading matplotlib-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\nRequirement already satisfied: numpy>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 7)) (1.24.4)\nCollecting numpy>=1.23.5 (from -r yolov5/requirements.txt (line 7))\n  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m795.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: opencv-python>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 8)) (4.9.0.80)\nRequirement already satisfied: Pillow>=9.4.0 in /opt/conda/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 9)) (9.5.0)\nCollecting Pillow>=9.4.0 (from -r yolov5/requirements.txt (line 9))\n  Downloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 10)) (5.9.3)\nCollecting psutil (from -r yolov5/requirements.txt (line 10))\n  Downloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\nRequirement already satisfied: PyYAML>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 11)) (6.0.1)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 12)) (2.31.0)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 13)) (1.11.4)\nCollecting scipy>=1.4.1 (from -r yolov5/requirements.txt (line 13))\n  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting thop>=0.1.1 (from -r yolov5/requirements.txt (line 14))\n  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 15)) (2.1.2)\nCollecting torch>=1.8.0 (from -r yolov5/requirements.txt (line 15))\n  Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 16)) (0.16.2)\nCollecting torchvision>=0.9.0 (from -r yolov5/requirements.txt (line 16))\n  Downloading torchvision-0.17.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 17)) (4.66.1)\nCollecting tqdm>=4.64.0 (from -r yolov5/requirements.txt (line 17))\n  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting ultralytics>=8.0.232 (from -r yolov5/requirements.txt (line 18))\n  Downloading ultralytics-8.1.19-py3-none-any.whl.metadata (40 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 27)) (2.1.4)\nCollecting pandas>=1.1.4 (from -r yolov5/requirements.txt (line 27))\n  Downloading pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 28)) (0.12.2)\nCollecting seaborn>=0.11.0 (from -r yolov5/requirements.txt (line 28))\n  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\nRequirement already satisfied: setuptools>=65.5.1 in /opt/conda/lib/python3.10/site-packages (from -r yolov5/requirements.txt (line 42)) (69.0.3)\nCollecting setuptools>=65.5.1 (from -r yolov5/requirements.txt (line 42))\n  Downloading setuptools-69.1.1-py3-none-any.whl.metadata (6.2 kB)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython>=3.1.30->-r yolov5/requirements.txt (line 5)) (4.0.11)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (2.8.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (2023.11.17)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (2023.12.2)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->-r yolov5/requirements.txt (line 15))\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->-r yolov5/requirements.txt (line 15))\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->-r yolov5/requirements.txt (line 15))\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->-r yolov5/requirements.txt (line 15))\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->-r yolov5/requirements.txt (line 15))\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->-r yolov5/requirements.txt (line 15))\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->-r yolov5/requirements.txt (line 15))\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->-r yolov5/requirements.txt (line 15))\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->-r yolov5/requirements.txt (line 15))\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.8.0->-r yolov5/requirements.txt (line 15))\n  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->-r yolov5/requirements.txt (line 15))\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.2.0 (from torch>=1.8.0->-r yolov5/requirements.txt (line 15))\n  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->-r yolov5/requirements.txt (line 15))\n  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics>=8.0.232->-r yolov5/requirements.txt (line 18)) (9.0.0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->-r yolov5/requirements.txt (line 27)) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->-r yolov5/requirements.txt (line 27)) (2023.4)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r yolov5/requirements.txt (line 5)) (5.0.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (1.3.0)\nDownloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading matplotlib-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\nDownloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.17.1-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ultralytics-8.1.19-py3-none-any.whl (716 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m716.2/716.2 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading setuptools-69.1.1-py3-none-any.whl (819 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.3/819.3 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton, tqdm, setuptools, psutil, Pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, scipy, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, gitpython, nvidia-cusolver-cu12, matplotlib, torch, seaborn, torchvision, thop, ultralytics\n  Attempting uninstall: tqdm\n    Found existing installation: tqdm 4.66.1\n    Uninstalling tqdm-4.66.1:\n      Successfully uninstalled tqdm-4.66.1\n  Attempting uninstall: setuptools\n    Found existing installation: setuptools 69.0.3\n    Uninstalling setuptools-69.0.3:\n      Successfully uninstalled setuptools-69.0.3\n  Attempting uninstall: psutil\n    Found existing installation: psutil 5.9.3\n    Uninstalling psutil-5.9.3:\n      Successfully uninstalled psutil-5.9.3\n  Attempting uninstall: Pillow\n    Found existing installation: Pillow 9.5.0\n    Uninstalling Pillow-9.5.0:\n      Successfully uninstalled Pillow-9.5.0\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.24.4\n    Uninstalling numpy-1.24.4:\n      Successfully uninstalled numpy-1.24.4\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.11.4\n    Uninstalling scipy-1.11.4:\n      Successfully uninstalled scipy-1.11.4\n  Attempting uninstall: pandas\n    Found existing installation: pandas 2.1.4\n    Uninstalling pandas-2.1.4:\n      Successfully uninstalled pandas-2.1.4\n  Attempting uninstall: gitpython\n    Found existing installation: GitPython 3.1.41\n    Uninstalling GitPython-3.1.41:\n      Successfully uninstalled GitPython-3.1.41\n  Attempting uninstall: matplotlib\n    Found existing installation: matplotlib 3.7.4\n    Uninstalling matplotlib-3.7.4:\n      Successfully uninstalled matplotlib-3.7.4\n  Attempting uninstall: torch\n    Found existing installation: torch 2.1.2\n    Uninstalling torch-2.1.2:\n      Successfully uninstalled torch-2.1.2\n  Attempting uninstall: seaborn\n    Found existing installation: seaborn 0.12.2\n    Uninstalling seaborn-0.12.2:\n      Successfully uninstalled seaborn-0.12.2\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.16.2\n    Uninstalling torchvision-0.16.2:\n      Successfully uninstalled torchvision-0.16.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\nbeatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.0.11 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.2.1 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ndask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.2.1 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.2.1 which is incompatible.\nfastai 2.7.13 requires torch<2.2,>=1.10, but you have torch 2.2.1 which is incompatible.\njupyterlab 4.0.11 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.2 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.8.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\npylibraft 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\nraft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\nrmm 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflowjs 4.16.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\nwoodwork 0.27.0 requires numpy<1.25.0,>=1.22.0, but you have numpy 1.26.4 which is incompatible.\nxarray 2024.1.0 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\nydata-profiling 4.6.4 requires scipy<1.12,>=1.4.1, but you have scipy 1.12.0 which is incompatible.\nydata-profiling 4.6.4 requires seaborn<0.13,>=0.10.1, but you have seaborn 0.13.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed Pillow-10.2.0 gitpython-3.1.42 matplotlib-3.8.2 numpy-1.26.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 pandas-2.2.0 psutil-5.9.7 scipy-1.12.0 seaborn-0.13.2 setuptools-69.1.1 thop-0.1.1.post2209072238 torch-2.2.1 torchvision-0.17.1 tqdm-4.66.2 triton-2.2.0 ultralytics-8.1.19\n[Errno 2] No such file or directory: '/content/yolov5'\n/kaggle/working\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Dataset Split","metadata":{}},{"cell_type":"markdown","source":"Preparing the data structure for training, validation and testing","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport shutil\nimport os\n\n# Define the base directory paths\nbase_dir = '/kaggle/input/fracatlas/FracAtlas'\nimages_dir = os.path.join(base_dir, 'images', 'Fractured')  # Path to the original images\nsplits_dir = os.path.join(base_dir, 'Utilities', 'Fracture Split')  # Path to the CSV files\n\n# Define the target directories for images\ntarget_images_dir = os.path.join('/kaggle/working/')\ntrain_dir = os.path.join(target_images_dir, 'train', 'images')\nval_dir = os.path.join(target_images_dir, 'val', 'images')\ntest_dir = os.path.join(target_images_dir, 'test', 'images')\n\n# Create target directories if they don't exist\nfor directory in [train_dir, val_dir, test_dir]:\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n# Function to copy images based on CSV file\ndef copy_images(csv_file, target_dir):\n    df = pd.read_csv(csv_file)\n    for index, row in df.iterrows():\n        image_file = row['image_id']  # Assuming 'image_name' column contains the image filenames\n        source_path = os.path.join(images_dir, image_file)\n        target_path = os.path.join(target_dir, image_file)\n        shutil.copy(source_path, target_path)\n\n# Copy images for each split\ncopy_images(os.path.join(splits_dir, 'train.csv'), train_dir)\ncopy_images(os.path.join(splits_dir, 'valid.csv'), val_dir)\ncopy_images(os.path.join(splits_dir, 'test.csv'), test_dir)\n\nprint(\"Images have been copied to the respective folders.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T18:06:22.735857Z","iopub.execute_input":"2024-02-27T18:06:22.736273Z","iopub.status.idle":"2024-02-27T18:06:31.789560Z","shell.execute_reply.started":"2024-02-27T18:06:22.736240Z","shell.execute_reply":"2024-02-27T18:06:31.788517Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Images have been copied to the respective folders.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Creating YOLO labels from COCO Annotations","metadata":{}},{"cell_type":"code","source":"import json\nimport os\nimport pandas as pd\n\n# Paths to the COCO annotation file, CSV files for splits, and the images directory\ncoco_annotation_path = '/kaggle/input/fracatlas/FracAtlas/Annotations/COCO JSON/COCO_fracture_masks.json'\ntrain_csv_path = '/kaggle/input/fracatlas/FracAtlas/Utilities/Fracture Split/train.csv'\nval_csv_path = '/kaggle/input/fracatlas/FracAtlas/Utilities/Fracture Split/valid.csv'\ntest_csv_path = '/kaggle/input/fracatlas/FracAtlas/Utilities/Fracture Split/test.csv'\nimages_base_path = '/kaggle/input/fracatlas/FracAtlas/images/Fractured'  # Update this path\n\n# Base directory where the YOLO labels should be saved\nbase_save_path = '/kaggle/working/'\n\ndef coco_to_yolo(box, img_w, img_h):\n    x, y, w, h = box\n    return [((x + w / 2) / img_w), ((y + h / 2) / img_h), (w / img_w), (h / img_h)]\n\ndef load_splits():\n    splits = {'train': pd.read_csv(train_csv_path),\n              'val': pd.read_csv(val_csv_path),\n              'test': pd.read_csv(test_csv_path)}\n    image_to_split = {}\n    for split_name, split_df in splits.items():\n        for img_id in split_df['image_id']:  # Adjust if the column name differs\n            image_to_split[img_id] = split_name\n    return image_to_split\n\nimage_to_split = load_splits()\n# print('Image to Split',image_to_split)\n\nwith open(coco_annotation_path, 'r') as f:\n    coco_data = json.load(f)\n\nfor img in coco_data['images']:\n    img_id = img['id']  # Use image ID to match with splits\n#     print('Img_id',img_id)\n    img_name = os.path.splitext(img['file_name'])[0]\n    split = image_to_split[img_name+'.jpg']\n    img_path = os.path.join(images_base_path, img['file_name'])  # Full path to the image file\n#     print('img_path',img_path)\n\n    # Proceed if the image exists\n    img_w, img_h = img['width'], img['height']\n    annotations = [ann for ann in coco_data['annotations'] if ann['image_id'] == img_id]\n#     print('Annotation',annotations)\n    yolo_labels = []\n    \n    for ann in annotations:\n        category_id = ann['category_id']  # Adjust based on your category mapping\n        box = coco_to_yolo(ann['bbox'], img_w, img_h)\n        yolo_labels.append([category_id, *box])\n    \n    labels_save_path = os.path.join(base_save_path, split, 'labels', f'{img_name}.txt')\n    os.makedirs(os.path.dirname(labels_save_path), exist_ok=True)\n#     print('yolo_labels', yolo_labels)\n    with open(labels_save_path, 'w') as label_file:\n        for label in yolo_labels:\n            label_file.write(' '.join(map(str, label)) + '\\n')\n\nprint(\"Conversion complete. Labels saved in YOLO format for existing images.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T18:06:31.791905Z","iopub.execute_input":"2024-02-27T18:06:31.792227Z","iopub.status.idle":"2024-02-27T18:06:31.993370Z","shell.execute_reply.started":"2024-02-27T18:06:31.792199Z","shell.execute_reply":"2024-02-27T18:06:31.991448Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Conversion complete. Labels saved in YOLO format for existing images.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"yaml_content = \"\"\"\npath: /kaggle/working/\ntrain: /kaggle/working/train\nval: /kaggle/working/val\nnc: 1  # Number of classes, adjust as per your dataset\nnames: ['Fractured']  # Adjust class names according to your dataset\n\"\"\"\n\nfile_path = '/kaggle/working/fracatlas_dataset.yml'  # Specify your desired file path\n\nwith open(file_path, 'w') as file:\n    file.write(yaml_content)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T18:06:32.006666Z","iopub.execute_input":"2024-02-27T18:06:32.006983Z","iopub.status.idle":"2024-02-27T18:06:32.014847Z","shell.execute_reply.started":"2024-02-27T18:06:32.006956Z","shell.execute_reply":"2024-02-27T18:06:32.013973Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom IPython.display import Image  # for displaying images\nprint('torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","metadata":{"execution":{"iopub.status.busy":"2024-02-27T18:06:32.015730Z","iopub.execute_input":"2024-02-27T18:06:32.015970Z","iopub.status.idle":"2024-02-27T18:06:34.225273Z","shell.execute_reply.started":"2024-02-27T18:06:32.015949Z","shell.execute_reply":"2024-02-27T18:06:34.224247Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"torch 2.2.1+cu121 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15102MB, multi_processor_count=40)\n","output_type":"stream"}]},{"cell_type":"code","source":"cd \"/kaggle/working/yolov5/\"","metadata":{"execution":{"iopub.status.busy":"2024-02-27T18:06:34.226591Z","iopub.execute_input":"2024-02-27T18:06:34.227042Z","iopub.status.idle":"2024-02-27T18:06:34.233392Z","shell.execute_reply.started":"2024-02-27T18:06:34.227011Z","shell.execute_reply":"2024-02-27T18:06:34.232458Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"/kaggle/working/yolov5\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Training the YOLO model","metadata":{}},{"cell_type":"code","source":"!python train.py --img 640 --batch 16 --epochs 25 --data /kaggle/working/fracatlas_dataset.yml --weights yolov5l6.pt --cache","metadata":{"execution":{"iopub.status.busy":"2024-02-27T18:07:46.873189Z","iopub.execute_input":"2024-02-27T18:07:46.873844Z","iopub.status.idle":"2024-02-27T18:22:52.489128Z","shell.execute_reply.started":"2024-02-27T18:07:46.873807Z","shell.execute_reply":"2024-02-27T18:22:52.487974Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n2024-02-27 18:08:02.569056: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-27 18:08:02.569178: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-27 18:08:02.883741: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5l6.pt, cfg=, data=/kaggle/working/fracatlas_dataset.yml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=25, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\nYOLOv5 🚀 v7.0-287-g574331f9 Python-3.10.13 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n\n\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\nDownloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n100%|████████████████████████████████████████| 755k/755k [00:00<00:00, 14.0MB/s]\nDownloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5l6.pt to yolov5l6.pt...\n100%|█████████████████████████████████████████| 147M/147M [00:00<00:00, 240MB/s]\n\nOverriding model.yaml nc=80 with nc=1\n\n                 from  n    params  module                                  arguments                     \n  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n  7                -1  1   3540480  models.common.Conv                      [512, 768, 3, 2]              \n  8                -1  3   5611008  models.common.C3                        [768, 768, 3]                 \n  9                -1  1   7079936  models.common.Conv                      [768, 1024, 3, 2]             \n 10                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n 11                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n 12                -1  1    787968  models.common.Conv                      [1024, 768, 1, 1]             \n 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 14           [-1, 8]  1         0  models.common.Concat                    [1]                           \n 15                -1  3   6200832  models.common.C3                        [1536, 768, 3, False]         \n 16                -1  1    394240  models.common.Conv                      [768, 512, 1, 1]              \n 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 18           [-1, 6]  1         0  models.common.Concat                    [1]                           \n 19                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n 20                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n 21                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 22           [-1, 4]  1         0  models.common.Concat                    [1]                           \n 23                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n 24                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n 25          [-1, 20]  1         0  models.common.Concat                    [1]                           \n 26                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n 27                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n 28          [-1, 16]  1         0  models.common.Concat                    [1]                           \n 29                -1  3   5807616  models.common.C3                        [1024, 768, 3, False]         \n 30                -1  1   5309952  models.common.Conv                      [768, 768, 3, 2]              \n 31          [-1, 12]  1         0  models.common.Concat                    [1]                           \n 32                -1  3  10496000  models.common.C3                        [1536, 1024, 3, False]        \n 33  [23, 26, 29, 32]  1     46152  models.yolo.Detect                      [1, [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], [256, 512, 768, 1024]]\nModel summary: 477 layers, 76162504 parameters, 76162504 gradients, 110.5 GFLOPs\n\nTransferred 787/795 items from yolov5l6.pt\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 131 weight(decay=0.0), 135 weight(decay=0.0005), 135 bias\nWARNING ⚠️ DP not recommended, use torch.distributed.run for best DDP Multi-GPU results.\nSee Multi-GPU Tutorial at https://docs.ultralytics.com/yolov5/tutorials/multi_gpu_training to get started.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/train/labels... 574 images, 0 backgrounds, 0 cor\u001b[0m\n\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/train/labels.cache\n\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.5GB ram): 100%|██████████| 574/574 [00:04<00:00, 123.61\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/val/labels... 82 images, 0 backgrounds, 0 corrupt:\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/val/labels.cache\n\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100%|██████████| 82/82 [00:00<00:00, 311.50it/s\u001b[0m\n\n\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.46 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\nPlotting labels to runs/train/exp/labels.jpg... \nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mruns/train/exp\u001b[0m\nStarting training for 25 epochs...\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       0/24      5.77G    0.08618    0.02012          0         41        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         82         91   8.13e-05      0.022   4.16e-05   4.16e-06\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       1/24      7.55G    0.07343    0.01671          0         26        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         82         91   0.000203     0.0549   0.000112   1.33e-05\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       2/24      7.55G    0.06414    0.01473          0         22        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         82         91   0.000407       0.11   0.000226   5.68e-05\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       3/24      7.55G    0.06453    0.01361          0         26        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         82         91    0.00232      0.626    0.00692    0.00198\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       4/24      7.55G    0.05797    0.01305          0         38        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         82         91    0.00264      0.714    0.00907    0.00212\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       5/24      7.55G    0.05712    0.01198          0         29        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         82         91     0.0934      0.209     0.0491     0.0133\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       6/24      7.55G    0.05276    0.01176          0         37        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         82         91      0.273      0.319      0.154     0.0386\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       7/24      7.55G    0.05319    0.01151          0         31        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         82         91      0.351      0.297      0.217     0.0587\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       8/24      7.55G    0.04973    0.01027          0         34        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         82         91      0.408      0.308      0.241     0.0614\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       9/24      7.55G    0.04899    0.01046          0         38        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         82         91      0.531      0.299      0.298     0.0872\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      10/24      7.55G    0.04137    0.01001          0         29        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         82         91      0.491      0.352      0.285      0.101\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      11/24      7.55G    0.04099   0.009929          0         24        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         82         91      0.442      0.407      0.322      0.109\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      12/24      7.55G    0.04445   0.009316          0         27        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         82         91      0.434      0.308        0.3      0.101\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      13/24      7.55G    0.03891   0.009686          0         30        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         82         91       0.45      0.431      0.378      0.133\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      14/24      7.55G    0.03911   0.009376          0         27        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         82         91      0.549      0.418      0.416      0.157\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      15/24      7.55G     0.0393    0.00897          0         31        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         82         91      0.524      0.339      0.354      0.124\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      16/24      7.55G    0.03443   0.008593          0         37        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         82         91      0.504      0.352      0.402      0.138\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      17/24      7.55G    0.03475   0.008419          0         28        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         82         91      0.606      0.418      0.431      0.165\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      18/24      7.55G    0.03501   0.008283          0         26        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         82         91      0.584      0.451      0.436      0.168\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      19/24      7.55G     0.0351   0.008339          0         23        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         82         91      0.589      0.535      0.509      0.194\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      20/24      7.55G    0.03229   0.007969          0         37        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         82         91        0.6      0.462      0.482      0.182\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      21/24      7.55G     0.0313   0.008104          0         30        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         82         91      0.647      0.483        0.5      0.183\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      22/24      7.55G     0.0306   0.007869          0         30        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         82         91      0.677      0.473      0.505      0.203\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      23/24      7.55G    0.02782   0.007747          0         30        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         82         91      0.656      0.525      0.552       0.22\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      24/24      7.55G    0.02801    0.00754          0         23        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         82         91      0.652      0.495      0.527      0.195\n\n25 epochs completed in 0.224 hours.\nOptimizer stripped from runs/train/exp/weights/last.pt, 153.0MB\nOptimizer stripped from runs/train/exp/weights/best.pt, 153.0MB\n\nValidating runs/train/exp/weights/best.pt...\nFusing layers... \nModel summary: 346 layers, 76118664 parameters, 0 gradients, 109.9 GFLOPs\n                 Class     Images  Instances          P          R      mAP50   \n                   all         82         91      0.656      0.525      0.552       0.22\nResults saved to \u001b[1mruns/train/exp\u001b[0m\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Detection of Fractures in Test Images","metadata":{}},{"cell_type":"code","source":"!python detect.py --weights runs/train/exp/weights/best.pt --img 640 --source /kaggle/working/test/images","metadata":{"execution":{"iopub.status.busy":"2024-02-27T18:23:52.796109Z","iopub.execute_input":"2024-02-27T18:23:52.796504Z","iopub.status.idle":"2024-02-27T18:24:07.060190Z","shell.execute_reply.started":"2024-02-27T18:23:52.796473Z","shell.execute_reply":"2024-02-27T18:24:07.058990Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp/weights/best.pt'], source=/kaggle/working/test/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\nYOLOv5 🚀 v7.0-287-g574331f9 Python-3.10.13 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n\nFusing layers... \nModel summary: 346 layers, 76118664 parameters, 0 gradients, 109.9 GFLOPs\nimage 1/61 /kaggle/working/test/images/IMG0003297.jpg: 640x576 (no detections), 89.5ms\nimage 2/61 /kaggle/working/test/images/IMG0003298.jpg: 640x576 1 Fractured, 46.7ms\nimage 3/61 /kaggle/working/test/images/IMG0003301.jpg: 640x576 (no detections), 46.9ms\nimage 4/61 /kaggle/working/test/images/IMG0003308.jpg: 640x576 (no detections), 46.7ms\nimage 5/61 /kaggle/working/test/images/IMG0003309.jpg: 576x640 1 Fractured, 93.1ms\nimage 6/61 /kaggle/working/test/images/IMG0003310.jpg: 640x576 1 Fractured, 46.8ms\nimage 7/61 /kaggle/working/test/images/IMG0003311.jpg: 640x576 2 Fractureds, 34.6ms\nimage 8/61 /kaggle/working/test/images/IMG0003312.jpg: 640x576 1 Fractured, 33.0ms\nimage 9/61 /kaggle/working/test/images/IMG0003313.jpg: 640x576 (no detections), 32.7ms\nimage 10/61 /kaggle/working/test/images/IMG0003331.jpg: 640x576 1 Fractured, 32.1ms\nimage 11/61 /kaggle/working/test/images/IMG0003332.jpg: 640x576 1 Fractured, 32.1ms\nimage 12/61 /kaggle/working/test/images/IMG0003338.jpg: 640x576 1 Fractured, 27.9ms\nimage 13/61 /kaggle/working/test/images/IMG0003339.jpg: 640x576 2 Fractureds, 27.9ms\nimage 14/61 /kaggle/working/test/images/IMG0003341.jpg: 576x640 (no detections), 28.7ms\nimage 15/61 /kaggle/working/test/images/IMG0003342.jpg: 640x576 (no detections), 29.0ms\nimage 16/61 /kaggle/working/test/images/IMG0003373.jpg: 640x576 (no detections), 28.1ms\nimage 17/61 /kaggle/working/test/images/IMG0003374.jpg: 640x576 1 Fractured, 27.0ms\nimage 18/61 /kaggle/working/test/images/IMG0003381.jpg: 640x576 1 Fractured, 27.9ms\nimage 19/61 /kaggle/working/test/images/IMG0003382.jpg: 640x576 1 Fractured, 28.7ms\nimage 20/61 /kaggle/working/test/images/IMG0003383.jpg: 640x576 1 Fractured, 28.6ms\nimage 21/61 /kaggle/working/test/images/IMG0003394.jpg: 640x576 (no detections), 28.9ms\nimage 22/61 /kaggle/working/test/images/IMG0003395.jpg: 640x576 (no detections), 28.4ms\nimage 23/61 /kaggle/working/test/images/IMG0003396.jpg: 640x576 1 Fractured, 27.4ms\nimage 24/61 /kaggle/working/test/images/IMG0003397.jpg: 640x576 1 Fractured, 26.6ms\nimage 25/61 /kaggle/working/test/images/IMG0003398.jpg: 640x576 1 Fractured, 28.3ms\nimage 26/61 /kaggle/working/test/images/IMG0003399.jpg: 640x576 (no detections), 29.1ms\nimage 27/61 /kaggle/working/test/images/IMG0003419.jpg: 640x576 (no detections), 29.6ms\nimage 28/61 /kaggle/working/test/images/IMG0003420.jpg: 576x640 1 Fractured, 28.9ms\nimage 29/61 /kaggle/working/test/images/IMG0003458.jpg: 640x576 1 Fractured, 27.8ms\nimage 30/61 /kaggle/working/test/images/IMG0003459.jpg: 640x576 1 Fractured, 26.6ms\nimage 31/61 /kaggle/working/test/images/IMG0003466.jpg: 640x576 2 Fractureds, 28.3ms\nimage 32/61 /kaggle/working/test/images/IMG0003467.jpg: 640x576 1 Fractured, 28.6ms\nimage 33/61 /kaggle/working/test/images/IMG0003477.jpg: 640x576 (no detections), 28.5ms\nimage 34/61 /kaggle/working/test/images/IMG0003509.jpg: 640x576 2 Fractureds, 28.6ms\nimage 35/61 /kaggle/working/test/images/IMG0003510.jpg: 640x576 1 Fractured, 27.8ms\nimage 36/61 /kaggle/working/test/images/IMG0003519.jpg: 640x576 1 Fractured, 27.0ms\nimage 37/61 /kaggle/working/test/images/IMG0003520.jpg: 640x576 1 Fractured, 27.5ms\nimage 38/61 /kaggle/working/test/images/IMG0003523.jpg: 640x576 1 Fractured, 28.0ms\nimage 39/61 /kaggle/working/test/images/IMG0003524.jpg: 640x576 (no detections), 28.6ms\nimage 40/61 /kaggle/working/test/images/IMG0003545.jpg: 640x576 (no detections), 29.7ms\nimage 41/61 /kaggle/working/test/images/IMG0003564.jpg: 640x576 1 Fractured, 28.2ms\nimage 42/61 /kaggle/working/test/images/IMG0003565.jpg: 640x576 1 Fractured, 26.8ms\nimage 43/61 /kaggle/working/test/images/IMG0003569.jpg: 640x576 1 Fractured, 27.5ms\nimage 44/61 /kaggle/working/test/images/IMG0003586.jpg: 640x576 1 Fractured, 28.8ms\nimage 45/61 /kaggle/working/test/images/IMG0003587.jpg: 640x576 1 Fractured, 29.0ms\nimage 46/61 /kaggle/working/test/images/IMG0003588.jpg: 640x576 1 Fractured, 28.7ms\nimage 47/61 /kaggle/working/test/images/IMG0003589.jpg: 640x576 1 Fractured, 28.2ms\nimage 48/61 /kaggle/working/test/images/IMG0003619.jpg: 640x576 (no detections), 27.5ms\nimage 49/61 /kaggle/working/test/images/IMG0003620.jpg: 640x576 (no detections), 26.5ms\nimage 50/61 /kaggle/working/test/images/IMG0003625.jpg: 640x576 1 Fractured, 27.5ms\nimage 51/61 /kaggle/working/test/images/IMG0003626.jpg: 640x576 1 Fractured, 27.6ms\nimage 52/61 /kaggle/working/test/images/IMG0003628.jpg: 576x640 2 Fractureds, 28.7ms\nimage 53/61 /kaggle/working/test/images/IMG0003653.jpg: 640x576 (no detections), 28.7ms\nimage 54/61 /kaggle/working/test/images/IMG0003654.jpg: 640x576 1 Fractured, 28.9ms\nimage 55/61 /kaggle/working/test/images/IMG0003671.jpg: 640x576 1 Fractured, 28.7ms\nimage 56/61 /kaggle/working/test/images/IMG0003685.jpg: 640x576 2 Fractureds, 28.2ms\nimage 57/61 /kaggle/working/test/images/IMG0003686.jpg: 640x576 1 Fractured, 27.7ms\nimage 58/61 /kaggle/working/test/images/IMG0003703.jpg: 640x576 1 Fractured, 26.5ms\nimage 59/61 /kaggle/working/test/images/IMG0003704.jpg: 640x576 (no detections), 26.7ms\nimage 60/61 /kaggle/working/test/images/IMG0003712.jpg: 640x576 1 Fractured, 29.1ms\nimage 61/61 /kaggle/working/test/images/IMG0003713.jpg: 640x576 1 Fractured, 29.1ms\nSpeed: 0.5ms pre-process, 31.8ms inference, 10.2ms NMS per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/exp\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"yaml_content = \"\"\"\npath: /kaggle/working/test  # Base path for the dataset\ntrain: /kaggle/working/train\nval: /kaggle/working/val\ntest: /kaggle/working/test  # Relative path from `path` to the test images\nnc: 1  # Number of classes\nnames: ['Fractured']  # Names of the classes\n\"\"\"\n\nfile_path = '/kaggle/working/fracatlas_test_dataset.yml'  # Specify your desired file path\n\nwith open(file_path, 'w') as file:\n    file.write(yaml_content)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T18:24:22.846585Z","iopub.execute_input":"2024-02-27T18:24:22.847332Z","iopub.status.idle":"2024-02-27T18:24:22.853518Z","shell.execute_reply.started":"2024-02-27T18:24:22.847272Z","shell.execute_reply":"2024-02-27T18:24:22.852473Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Evaluating the model on Test Image to obtain the metrics","metadata":{}},{"cell_type":"code","source":"!python val.py --data /kaggle/working/fracatlas_test_dataset.yml --weights runs/train/exp/weights/best.pt --img 640 --task test --conf-thres 0.25 --iou-thres 0.5","metadata":{"execution":{"iopub.status.busy":"2024-02-27T18:24:24.586409Z","iopub.execute_input":"2024-02-27T18:24:24.586775Z","iopub.status.idle":"2024-02-27T18:24:41.868703Z","shell.execute_reply.started":"2024-02-27T18:24:24.586747Z","shell.execute_reply":"2024-02-27T18:24:41.867618Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mdata=/kaggle/working/fracatlas_test_dataset.yml, weights=['runs/train/exp/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.25, iou_thres=0.5, max_det=300, task=test, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\nWARNING ⚠️ confidence threshold 0.25 > 0.001 produces invalid results\nYOLOv5 🚀 v7.0-287-g574331f9 Python-3.10.13 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n\nFusing layers... \nModel summary: 346 layers, 76118664 parameters, 0 gradients, 109.9 GFLOPs\n\u001b[34m\u001b[1mtest: \u001b[0mScanning /kaggle/working/test/labels... 61 images, 0 backgrounds, 0 corrup\u001b[0m\n\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: /kaggle/working/test/labels.cache\n                 Class     Images  Instances          P          R      mAP50   \n                   all         61         67      0.663      0.433      0.521      0.258\nSpeed: 0.3ms pre-process, 27.9ms inference, 9.3ms NMS per image at shape (32, 3, 640, 640)\nResults saved to \u001b[1mruns/val/exp\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}